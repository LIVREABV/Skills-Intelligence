{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b304a3a9-488c-478f-91d5-18c1d03cfcb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1 Install + imports\n",
    "%pip install chromadb openai\n",
    "%pip install -U hnswlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "656314d8-2e87-4fd8-9882-d848c7185cbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 2 Init Chroma Persistent DB (di DBFS)\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "PERSIST_DIR = \"/Volumes/skills_intelligence/temp/temp/chroma_skills_intelligence\"\n",
    "COLLECTION_NAME = \"financial_sector_data_or_bi_analyst_chunks\"\n",
    "\n",
    "os.makedirs(PERSIST_DIR, exist_ok=True)\n",
    "\n",
    "settings = Settings(\n",
    "    chroma_api_impl=\"chromadb.api.segment.SegmentAPI\",  # âœ… embedded/local mode\n",
    "    persist_directory=PERSIST_DIR\n",
    ")\n",
    "\n",
    "chroma_client = chromadb.Client(settings)\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=dbutils.secrets.get(\"openai\", \"api_key\"),\n",
    "    model_name=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    embedding_function=openai_ef\n",
    ")\n",
    "\n",
    "print(\"Chroma path:\", PERSIST_DIR)\n",
    "print(\"Collection:\", COLLECTION_NAME)\n",
    "print(\"Count:\", collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39c688e2-067c-41d8-bbb9-fdf1c5b609e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 3 Make the chunks of data\n",
    "\n",
    "SRC_CHUNKS = \"skills_intelligence.02_silver.financial_sector_data_or_bi_analyst_core_chunks\"\n",
    "\n",
    "df = (\n",
    "    spark.table(SRC_CHUNKS)\n",
    "    .select(\"chunk_hash\", \"chunk\", \"Company\", \"row_hash\", \"chunk_len\", \"created_at\")\n",
    "    .where(F.col(\"chunk\").isNotNull())\n",
    "    .where(F.length(\"chunk\") > 0)\n",
    "    .dropDuplicates([\"chunk_hash\"])   # penting: karena chunk_hash jadi ID\n",
    ")\n",
    "\n",
    "print(\"Rows to embed:\", df.count())\n",
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8069ebe5-47b9-412b-af74-b6e5751b6d3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 4 Upsert to Chroma\n",
    "\n",
    "BATCH_SIZE = 128  # bisa 64/128/256. mulai 128 biar stabil.\n",
    "\n",
    "batch_ids, batch_docs, batch_metas = [], [], []\n",
    "total = 0\n",
    "\n",
    "rows_iter = df.toLocalIterator()\n",
    "\n",
    "for r in rows_iter:\n",
    "    batch_ids.append(str(r[\"chunk_hash\"]))\n",
    "    batch_docs.append(str(r[\"chunk\"]))\n",
    "    batch_metas.append({\n",
    "        \"Company\": str(r[\"Company\"]),\n",
    "        \"row_hash\": str(r[\"row_hash\"]),\n",
    "        \"chunk_len\": int(r[\"chunk_len\"]) if r[\"chunk_len\"] is not None else None,\n",
    "        \"created_at\": str(r[\"created_at\"]) if r[\"created_at\"] is not None else None,\n",
    "        \"source_table\": SRC_CHUNKS\n",
    "    })\n",
    "\n",
    "    if len(batch_ids) >= BATCH_SIZE:\n",
    "        # upsert jika tersedia, else add\n",
    "        if hasattr(collection, \"upsert\"):\n",
    "            collection.upsert(ids=batch_ids, documents=batch_docs, metadatas=batch_metas)\n",
    "        else:\n",
    "            collection.add(ids=batch_ids, documents=batch_docs, metadatas=batch_metas)\n",
    "\n",
    "        total += len(batch_ids)\n",
    "        batch_ids, batch_docs, batch_metas = [], [], []\n",
    "        print(\"Upserted:\", total)\n",
    "\n",
    "# flush sisa batch\n",
    "if batch_ids:\n",
    "    if hasattr(collection, \"upsert\"):\n",
    "        collection.upsert(ids=batch_ids, documents=batch_docs, metadatas=batch_metas)\n",
    "    else:\n",
    "        collection.add(ids=batch_ids, documents=batch_docs, metadadatas=batch_metas)\n",
    "\n",
    "    total += len(batch_ids)\n",
    "\n",
    "print(\"DONE. Total upserted:\", total)\n",
    "print(\"Collection count now:\", collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "885a77ae-5665-40ba-92d0-b607d1820ad7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 5 Query test to Chroma\n",
    "\n",
    "q = \"stakeholder management communication data analysis reporting\"\n",
    "res = collection.query(\n",
    "    query_texts=[q],\n",
    "    n_results=5,\n",
    "    include=[\"documents\", \"metadatas\", \"distances\"]\n",
    ")\n",
    "\n",
    "for i in range(4):\n",
    "    print(\"\\n---\", i+1, \"---\")\n",
    "    print(\"distance:\", res[\"distances\"][0][i])\n",
    "    print(\"Company :\", res[\"metadatas\"][0][i].get(\"Company\"))\n",
    "    print(res[\"documents\"][0][i][:350], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ab9e901-af2e-4acf-974d-8e1163e8345e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 6 Set up the GPT and check the soft_skill_livrea\n",
    "\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "CHAT_MODEL = \"gpt-4o-mini\"\n",
    "client = OpenAI(api_key=dbutils.secrets.get(\"openai\", \"api_key\"))\n",
    "\n",
    "SOFT_TABLE = \"skills_intelligence.01_bronze.livrea_soft_skill\"\n",
    "\n",
    "pdf_soft = (\n",
    "    spark.table(SOFT_TABLE)\n",
    "    .select(\"soft_skill\", \"description\")\n",
    "    .where(F.col(\"soft_skill\").isNotNull())\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "pdf_soft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dbcd208-b393-40c3-ac17-c7b5457d783f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 7 Check again the Chroma\n",
    "\n",
    "import os\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "PERSIST_DIR = \"/Volumes/skills_intelligence/temp/temp/chroma_skills_intelligence\"\n",
    "COLLECTION_NAME = \"financial_sector_data_or_bi_analyst_chunks\"\n",
    "\n",
    "os.makedirs(PERSIST_DIR, exist_ok=True)\n",
    "\n",
    "settings = Settings(\n",
    "    chroma_api_impl=\"chromadb.api.segment.SegmentAPI\",\n",
    "    persist_directory=PERSIST_DIR\n",
    ")\n",
    "chroma_client = chromadb.Client(settings)\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=dbutils.secrets.get(\"openai\", \"api_key\"),\n",
    "    model_name=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    embedding_function=openai_ef\n",
    ")\n",
    "\n",
    "print(\"Chroma count:\", collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e29e2020-3a0a-485e-bff2-3c27f7e35196",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 8 Set up the System Prompt for the GPT\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an HR analytics rater.\n",
    "Rate how relevant a given soft skill is for a Financial Sector Data/BI Analyst job market,\n",
    "based ONLY on the provided evidence snippets from job descriptions.\n",
    "\n",
    "Return ONLY valid JSON with this schema:\n",
    "{\n",
    "  \"soft_skill\": \"string\",\n",
    "  \"score\": number,              // 0..1\n",
    "  \"rationale\": \"string\",        // 1-2 short sentences\n",
    "  \"evidence_companies\": [\"string\", ...]\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- score must be between 0 and 1 inclusive.\n",
    "- be consistent: 0.0 = not present at all, 1.0 = strongly and repeatedly required.\n",
    "- do not output anything other than JSON.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7887a446-9fa7-45e3-9392-8d16cd28fd87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 8 Set up the System Prompt for the GPT\n",
    "\n",
    "def build_evidence_block(res, max_chars_per_snippet=450):\n",
    "    docs = res[\"documents\"][0]\n",
    "    metas = res[\"metadatas\"][0]\n",
    "    dists = res.get(\"distances\", [[None]*len(docs)])[0]\n",
    "\n",
    "    lines = []\n",
    "    companies = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        comp = (metas[i] or {}).get(\"Company\", \"Unknown\")\n",
    "        companies.append(comp)\n",
    "        snippet = doc.strip().replace(\"\\n\", \" \")\n",
    "        if len(snippet) > max_chars_per_snippet:\n",
    "            snippet = snippet[:max_chars_per_snippet].rstrip() + \"...\"\n",
    "        dist = dists[i]\n",
    "        lines.append(f\"- ({comp}) [distance={dist}] {snippet}\")\n",
    "\n",
    "    return \"\\n\".join(lines), sorted(list(set(companies)))\n",
    "\n",
    "def call_gpt_score(soft_skill: str, desc: str, evidence_text: str, companies: list, max_retries=3):\n",
    "    user_prompt = f\"\"\"\n",
    "Soft skill:\n",
    "- soft_skill: {soft_skill}\n",
    "- description: {desc}\n",
    "\n",
    "Evidence snippets (top matches from job descriptions):\n",
    "{evidence_text}\n",
    "\n",
    "Provide the JSON result now.\n",
    "\"\"\"\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(1, max_retries+1):\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=CHAT_MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt},\n",
    "                ],\n",
    "                temperature=0.0\n",
    "            )\n",
    "            raw = resp.choices[0].message.content.strip()\n",
    "\n",
    "            # Parse JSON robustly (strip code fences if any)\n",
    "            raw = raw.strip(\"`\").strip()\n",
    "            data = json.loads(raw)\n",
    "\n",
    "            # enforce schema + bounds\n",
    "            score = float(data.get(\"score\", 0.0))\n",
    "            score = max(0.0, min(1.0, score))\n",
    "            out = {\n",
    "                \"soft_skill\": soft_skill,\n",
    "                \"score\": score,\n",
    "                \"rationale\": str(data.get(\"rationale\", \"\")).strip(),\n",
    "                \"evidence_companies\": data.get(\"evidence_companies\", companies) or companies\n",
    "            }\n",
    "            return out, raw\n",
    "\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(1.2 * attempt)\n",
    "\n",
    "    raise last_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a25044c0-86e9-4807-871e-1f1ebc2cd13f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 9 Get top K matches for each soft skill from the Chroma and give it to GPT to score 0-10\n",
    "\n",
    "TOP_K = 5\n",
    "results = []\n",
    "\n",
    "for idx, r in pdf_soft.iterrows():\n",
    "    soft_skill = str(r[\"soft_skill\"]).strip()\n",
    "    desc = \"\" if pd.isna(r[\"description\"]) else str(r[\"description\"]).strip()\n",
    "\n",
    "    query = f\"{soft_skill}. {desc}\".strip()\n",
    "\n",
    "    res = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=TOP_K,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "\n",
    "    evidence_text, companies = build_evidence_block(res, max_chars_per_snippet=450)\n",
    "\n",
    "    scored, raw_json = call_gpt_score(\n",
    "        soft_skill=soft_skill,\n",
    "        desc=desc,\n",
    "        evidence_text=evidence_text,\n",
    "        companies=companies,\n",
    "        max_retries=3\n",
    "    )\n",
    "\n",
    "    scored[\"top_k\"] = TOP_K\n",
    "    scored[\"query_text\"] = query\n",
    "    scored[\"scored_at\"] = pd.Timestamp.utcnow().isoformat()\n",
    "    scored[\"model\"] = CHAT_MODEL\n",
    "\n",
    "    results.append(scored)\n",
    "\n",
    "    if (idx + 1) % 5 == 0:\n",
    "        print(f\"Scored {idx+1}/{len(pdf_soft)} soft skills\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fe1a3df-62ba-4672-898e-69e9c7604593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 10 Check the result\n",
    "\n",
    "results[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c66bd6a-8036-40ea-b331-6d492ee45fce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 11 store to Golden\n",
    "\n",
    "target = \"skills_intelligence.03_golden.financial_sector_data_or_bi_analyst_x_livrea_soft_skill\"\n",
    "\n",
    "df_out = spark.createDataFrame(pd.DataFrame(results)) \\\n",
    "    .withColumn(\"scored_at_ts\", F.current_timestamp())\n",
    "\n",
    "(\n",
    "    df_out\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(target)\n",
    ")\n",
    "\n",
    "print(\"Saved:\", target)\n",
    "display(spark.table(target).orderBy(F.desc(\"score\")).limit(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53735474-7c5b-493c-a789-015866c5cd7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_embedding_to_chroma_and_gpt_scoring",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
